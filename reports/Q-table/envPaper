--------------------------------------------------------------------------------
Environment: DiscreteToyEnvPaper
  States: 3
  Leader actions: 2
  Follower actions: 3
  Discount: 0.8
  Temperature: 1.0
--------------------------------------------------------------------------------
  Iteration 100: max_delta = 0.000000

âœ“ True Q-values converged in 157 iterations (max_delta=0.000000)

================================================================================
TRUE Q-VALUES: Q_F^*(s, a, b)
================================================================================

State 0:
  Leader a=0: Q(0,0,0)=  5.5917  Q(0,0,1)=  5.8894  Q(0,0,2)=  6.1225
  Leader a=1: Q(0,1,0)=  5.5917  Q(0,1,1)=  5.8894  Q(0,1,2)=  6.1225

State 1:
  Leader a=0: Q(1,0,0)=  4.5917  Q(1,0,1)=  4.8894  Q(1,0,2)=  6.1225
  Leader a=1: Q(1,1,0)=  4.5917  Q(1,1,1)=  4.5917  Q(1,1,2)=  4.5917

State 2:
  Leader a=0: Q(2,0,0)=  5.5917  Q(2,0,1)=  5.1225  Q(2,0,2)=  5.1225
  Leader a=1: Q(2,1,0)=  5.5917  Q(2,1,1)=  5.1225  Q(2,1,2)=  5.1225

--------------------------------------------------------------------------------
Q-value Statistics:
  Min:    4.5917
  Max:    6.1225
  Mean:   5.3477
  Std:    0.5439
================================================================================
