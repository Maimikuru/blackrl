--------------------------------------------------------------------------------
Environment: DiscreteToyEnv1_1a
  States: 3
  Leader actions: 2
  Follower actions: 3
  Discount: 0.8
  Temperature: 1.0
--------------------------------------------------------------------------------

âœ“ True Q-values converged in 53 iterations (max_delta=0.000009)

================================================================================
TRUE Q-VALUES: Q_F^*(s, a, b)
================================================================================

State 0:
  Leader a=0: Q(0,0,0)=  4.6403  Q(0,0,1)=  5.1536  Q(0,0,2)=  3.9852
  Leader a=1: Q(0,1,0)=  4.6403  Q(0,1,1)=  3.9852  Q(0,1,2)=  5.1536

State 1:
  Leader a=0: Q(1,0,0)=  5.6403  Q(1,0,1)=  5.1536  Q(1,0,2)=  5.1536
  Leader a=1: Q(1,1,0)=  5.6403  Q(1,1,1)=  5.1536  Q(1,1,2)=  5.1536

State 2:
  Leader a=0: Q(2,0,0)=  3.6403  Q(2,0,1)=  3.9852  Q(2,0,2)=  3.9852
  Leader a=1: Q(2,1,0)=  3.6403  Q(2,1,1)=  3.9852  Q(2,1,2)=  3.9852

--------------------------------------------------------------------------------
Q-value Statistics:
  Min:    3.6403
  Max:    5.6403
  Mean:   4.5930
  Std:    0.6715
================================================================================