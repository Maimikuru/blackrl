Computing true Q-values for follower...
--------------------------------------------------------------------------------
Environment: DiscreteToyEnv4_1a
  States: 3
  Leader actions: 2
  Follower actions: 3
  Discount: 0.8
  Temperature: 1.0
--------------------------------------------------------------------------------

âœ“ True Q-values converged in 54 iterations (max_delta=0.000008)

================================================================================
TRUE Q-VALUES: Q_F^*(s, a, b)
================================================================================

State 0:
  Leader a=0: Q(0,0,0)=  5.6565  Q(0,0,1)=  6.0293  Q(0,0,2)=  6.1640
  Leader a=1: Q(0,1,0)=  5.6565  Q(0,1,1)=  6.0293  Q(0,1,2)=  6.1640

State 1:
  Leader a=0: Q(1,0,0)=  5.6565  Q(1,0,1)=  5.0293  Q(1,0,2)=  6.1640
  Leader a=1: Q(1,1,0)=  4.6565  Q(1,1,1)=  4.6565  Q(1,1,2)=  4.6565

State 2:
  Leader a=0: Q(2,0,0)=  5.6565  Q(2,0,1)=  5.1640  Q(2,0,2)=  5.1640
  Leader a=1: Q(2,1,0)=  5.6565  Q(2,1,1)=  5.1640  Q(2,1,2)=  5.1640

--------------------------------------------------------------------------------
Q-value Statistics:
  Min:    4.6565
  Max:    6.1640
  Mean:   5.4715
  Std:    0.5163
================================================================================